{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align:center'>\n",
    "PSY 394U <b>Methods for fMRI</b>, Fall 2018\n",
    "\n",
    "\n",
    "<img style='width: 300px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Placebo_Left.png?raw=true' alt='brain blobs'/>\n",
    "\n",
    "</p>\n",
    "\n",
    "<p style='text-align:center; font-size:40px; margin-bottom: 30px;'><b>Neuroimaging data structure</b></p>\n",
    "\n",
    "<p style='text-align:center; font-size:18px; margin-bottom: 32px;'><b>September 24, 2018</b></p>\n",
    "\n",
    "<hr style='height:5px;border:none' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DICOM to NIfTI conversion\n",
    "<hr style=\"height:1px;border:none\" />\n",
    "\n",
    "MRI scanners typically produce image data in their own format. The most common image data format from MRI scanners is DICOM. However, most neuroimaging analysis tools are not designed to handle DICOM images. Thus, first you need to convert DICOM to NIfTI format images. \n",
    "\n",
    "I do not cover details here, since this conversion is something you only need to do once, and there are a number of tools to do so. Here are some popular tools to convert DICOM images to NIfTI images:\n",
    "\n",
    "* **dcm2niix**: (https://www.nitrc.org/plugins/mwiki/index.php/dcm2nii:MainPage)\n",
    "* **mri_convert**: (https://surfer.nmr.mgh.harvard.edu/fswiki/mri_convert)\n",
    "* **spm12** (Siemens only): (https://www.fil.ion.ucl.ac.uk/spm/software/spm12/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIfTI file format (`.nii`)\n",
    "<hr style=\"height:1px;border:none\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is NIfTI format?\n",
    "\n",
    "**NIfTI** stands for *Neuroimaging Informatics Technology Initiative*, with **`.nii`** extension. Before the NIfTI format, the predominant file format for neuroimaging research was the Analyze format (with `.hdr` and `.img` files). However, different software packages embedded different information in image data files, and consequently image data were not truly compatible once it has been processed in a certain software package. To address this issue, the NIfTI format was introduced. Today, most neuroimaging data are in the NIfTI format.\n",
    "\n",
    "A NIfTI file consists of the header information (first 348 Bytes) and the image data (the rest of the file).\n",
    "\n",
    "## NIfTI header\n",
    "\n",
    "A typical NIfTI header includes a number of fields describing information regarding the image. Let's take a look at an example from an fMRI image. I am using the same file from the previous class (`ds102` data set, subject 26). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<ViewHeader.py>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : b''\n",
      "db_name         : b''\n",
      "extents         : 0\n",
      "session_error   : 0\n",
      "regular         : b'r'\n",
      "dim_info        : 0\n",
      "dim             : [  4  64  64  40 146   1   1   1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : int16\n",
      "bitpix          : 16\n",
      "slice_start     : 0\n",
      "pixdim          : [1. 3. 3. 4. 2. 0. 0. 0.]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 10\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 0\n",
      "glmin           : 0\n",
      "descrip         : b'FSL4.0'\n",
      "aux_file        : b''\n",
      "qform_code      : scanner\n",
      "sform_code      : scanner\n",
      "quatern_b       : 0.0\n",
      "quatern_c       : 0.0\n",
      "quatern_d       : 0.0\n",
      "qoffset_x       : -94.5\n",
      "qoffset_y       : -108.95783\n",
      "qoffset_z       : -67.87952\n",
      "srow_x          : [  3.    0.    0.  -94.5]\n",
      "srow_y          : [   0.         3.         0.      -108.95783]\n",
      "srow_z          : [  0.        0.        4.      -67.87952]\n",
      "intent_name     : b''\n",
      "magic           : b'n+1'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "\n",
    "# Directory where your data set resides. This needs to be customized\n",
    "dataDir = '/home/satoru/Teaching/fMRI_Fall_2018/Data/ds102'\n",
    "\n",
    "# reading in the fMRI data array\n",
    "f_fMRI = os.path.join(dataDir,'sub-26/func/sub-26_task-flanker_run-2_bold.nii.gz')\n",
    "fMRI = nib.load(f_fMRI)   # image object\n",
    "\n",
    "# priting out the header information\n",
    "hdr_fMRI = fMRI.header\n",
    "print(hdr_fMRI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of methods associated with the NIfTI header that provide you information you may be interested. First, the image dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 40, 146)\n"
     ]
    }
   ],
   "source": [
    "# image dimension\n",
    "print(hdr_fMRI.get_data_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the first 3 elements (**`64  64  40`**) show the number of voxels in the x, y, and z dimensions. The 4th element (**`146`**) is the number of time points in this fMRI time series. \n",
    "\n",
    "Next, data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int16\n"
     ]
    }
   ],
   "source": [
    "# data type\n",
    "print(hdr_fMRI.get_data_dtype())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that, the data format for each voxel value is **`int16`**, or 16-bit integer. If you ever want to change the data type to another format, you can use the **`set_data_dtype()`** method associated with the header. For example,\n",
    "```python\n",
    "hdr_fMRI.set_data_dtype('float32')\n",
    "```\n",
    "sets the data type to be 32-bit float.\n",
    "\n",
    "The voxel size can be viewed by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3.0, 3.0, 4.0, 2.0)\n"
     ]
    }
   ],
   "source": [
    "# voxel size\n",
    "print(hdr_fMRI.get_zooms())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the first 3 elements correspond to voxel sizes in mm in x-, y-, and z-directions, respectively. The last element refers to the repetition time (TR, time between scans) in seconds.\n",
    "\n",
    "### Exercise\n",
    "1. **Header info, T1 image**. Get the image dimension, data type, and voxel size from the T1 image of a randomly selected subject from the data set `ds102`. Post the resulting information (rather than the code) on Canvas.\n",
    "2. **Header info, fMRI data, ds114**. Get the image dimension, data type, and voxel size from the fMRI data of a randomly selected subject from the data set `ds114`. Post the resulting information (rather than the code) on Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful piece of information in the NIfTI header is the affine information. It is a 4x4 matrix that lets you transform the voxel coordinates. This is what the affine matrix looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<AffineInfo.py>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  -1.           -0.           -0.           -1.44578552]\n",
      " [  -0.            1.           -0.         -127.5       ]\n",
      " [   0.            0.            1.         -125.33132935]\n",
      " [   0.            0.            0.            1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "\n",
    "# Directory where your data set resides. This needs to be customized\n",
    "dataDir = '/home/satoru/Teaching/fMRI_Fall_2018/Data/ds102'\n",
    "\n",
    "# reading in the T1 data array\n",
    "f_sMRI = os.path.join(dataDir,'sub-26/anat/sub-26_T1w.nii.gz')\n",
    "sMRI = nib.load(f_sMRI)\n",
    "X_sMRI = sMRI.get_data()\n",
    "\n",
    "# affine matrix\n",
    "print(sMRI.affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that, although this information is embedded in the header, we use the **`affine`** method associated with the *image object*, not the *header*. So, why should we care about this matrix? This matrix lets you transform array indices into the voxel coordinates in the brain space. Say, you want to see where the voxel `[85, 110, 140]` is located in the brain space (in terms of mm). \n",
    "\n",
    "To do so, you create a vector with the desired indices, plus 1 as the fourth element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example voxel indices\n",
    "xyz = np.array([[85, 110, 140]])\n",
    "xyz1 = np.hstack([xyz,np.array([[1]])]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 85],\n",
       "       [110],\n",
       "       [140],\n",
       "       [  1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xyz1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you multiply this with the affine matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming array indices to brain space coordinate\n",
    "A = sMRI.affine\n",
    "brain_xyz = np.dot(A,xyz1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-86.44578552],\n",
       "       [-17.5       ],\n",
       "       [ 14.66867065],\n",
       "       [  1.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain_xyz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the first 3 elements correspond to the voxel coordinate in the brain space, in terms of mm. You can verify this with an image viewer. For example, in FSL,\n",
    "\n",
    "<img style='width: 650px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Affine_Viewer.png?raw=true' alt='Affine viewer'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to transform the voxel coordinates in the brain space (in mm) to the corresponding array indices, simply finding the inverse of the affine matrix. For example, take the coordinate `[0, 0, 0]`mm in the brain space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voxel coordinate in mm\n",
    "xyzmm = np.array([[0, 0, 0]])\n",
    "xyz1mm = np.hstack([xyzmm,np.array([[1]])]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xyz1mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming brain space coordinate (in mm) to array indices\n",
    "invA = np.linalg.inv(A)\n",
    "voxel_xyz = np.dot(invA,xyz1mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.44578552],\n",
       "       [127.5       ],\n",
       "       [125.33132935],\n",
       "       [  1.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voxel_xyz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can check with an image viewer.\n",
    "\n",
    "<img style='width: 650px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Affine_Inverse.png?raw=true' alt='Affine viewer'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this image is the raw data, thus the center of the image `[0, 0, 0]`(in the brain space) is at an arbitrary location. During the preprocessing, the center is usually placed in the anterior commissure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NIfTI data matrix\n",
    "\n",
    "This portion of a NIfTI file consists of a series of 3D or 4D voxel intensities stored in a long sequence of numbers. There are several conventions to store voxel intensities such as:\n",
    "  * **RAS**\n",
    "      * First axis: x-axis left to **R**ight\n",
    "      * Second axis: y-axis posterior to **A**nterior\n",
    "      * Third axis: z-axis inferior to **S**uperior\n",
    "  * **LAS**\n",
    "      * First axis: x-axis right to **L**eft\n",
    "      * Second axis: y-axis posterior to **A**nterior\n",
    "      * Third axis: z-axis inferior to **S**uperior\n",
    "      \n",
    "Unless your data set consists of images acquired from different scanners with different protocols, you do not have to worry about how data are stored in a NIfTI file. Most image viewers and analysis software tools can display and process images in the desired orientation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Radiological vs. Neurological\n",
    "\n",
    "One thing you have to deal with, in your analysis as well as when you read the neuroimaging literature, is the orientation how the brain is displayed. There are two conventions:\n",
    "  * Neurological: \n",
    "      * Patient's left is displayed on the left\n",
    "  * Radiological:\n",
    "      * Patient's left is displayed on the right\n",
    "      \n",
    "<img style='width: 400px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Affine_radio_neuro.jpg?raw=true' alt='Neurological or radiological'/>\n",
    "\n",
    "\n",
    "When you examine image data, make sure which side of the subject is displayed on which side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIDS\n",
    "<hr style=\"height:1px;border:none\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is BIDS?\n",
    "* BIDS format\n",
    "    * Hierarchical organization\n",
    "        * Data\n",
    "        * Subject\n",
    "        * Session\n",
    "        * Data type\n",
    "    * File types\n",
    "        * Case sensitive\n",
    "        * Image (.nii)\n",
    "        * Table (.tsv)\n",
    "        * Other (.json)\n",
    "    * File name specification\n",
    "        * anatomical\n",
    "        * functional\n",
    "            * Sessions, runs, etc.\n",
    "        * diffusion\n",
    "* pybids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
