{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align:center'>\n",
    "PSY 394U <b>Methods for fMRI</b>, Fall 2018\n",
    "\n",
    "\n",
    "<img style='width: 300px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Placebo_Left.png?raw=true' alt='brain blobs'/>\n",
    "\n",
    "</p>\n",
    "\n",
    "<p style='text-align:center; font-size:40px; margin-bottom: 30px;'><b>Neuroimaging data structure</b></p>\n",
    "\n",
    "<p style='text-align:center; font-size:18px; margin-bottom: 32px;'><b>September 24, 2018</b></p>\n",
    "\n",
    "<hr style='height:5px;border:none' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DICOM to NIfTI conversion\n",
    "<hr style=\"height:1px;border:none\" />\n",
    "\n",
    "MRI scanners typically produce image data in their own format. The most common image data format from MRI scanners is DICOM. However, most neuroimaging analysis tools are not designed to handle DICOM images. Thus, first you need to convert DICOM to NIfTI format images. \n",
    "\n",
    "I do not cover details here, since this conversion is something you only need to do once, and there are a number of tools to do so. Here are some popular tools to convert DICOM images to NIfTI images:\n",
    "\n",
    "* **dcm2niix**: (https://www.nitrc.org/plugins/mwiki/index.php/dcm2nii:MainPage)\n",
    "* **mri_convert**: (https://surfer.nmr.mgh.harvard.edu/fswiki/mri_convert)\n",
    "* **spm12** (Siemens only): (https://www.fil.ion.ucl.ac.uk/spm/software/spm12/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIfTI file format (`.nii`)\n",
    "<hr style=\"height:1px;border:none\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is NIfTI format?\n",
    "\n",
    "**NIfTI** stands for *Neuroimaging Informatics Technology Initiative*, with **`.nii`** extension. Before the NIfTI format, the predominant file format for neuroimaging research was the Analyze format (with `.hdr` and `.img` files). However, different software packages embedded different information in image data files, and consequently image data were not truly compatible once it has been processed in a certain software package. To address this issue, the NIfTI format was introduced. Today, most neuroimaging data are in the NIfTI format.\n",
    "\n",
    "A NIfTI file consists of the header information (first 348 Bytes) and the image data (the rest of the file).\n",
    "\n",
    "## NIfTI header\n",
    "\n",
    "A typical NIfTI header includes a number of fields describing information regarding the image. Let's take a look at an example from an fMRI image. I am using the same file from the previous class (`ds102` data set, subject 26). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<ViewHeader.py>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : b''\n",
      "db_name         : b''\n",
      "extents         : 0\n",
      "session_error   : 0\n",
      "regular         : b'r'\n",
      "dim_info        : 0\n",
      "dim             : [  4  64  64  40 146   1   1   1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : int16\n",
      "bitpix          : 16\n",
      "slice_start     : 0\n",
      "pixdim          : [1. 3. 3. 4. 2. 0. 0. 0.]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 10\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 0\n",
      "glmin           : 0\n",
      "descrip         : b'FSL4.0'\n",
      "aux_file        : b''\n",
      "qform_code      : scanner\n",
      "sform_code      : scanner\n",
      "quatern_b       : 0.0\n",
      "quatern_c       : 0.0\n",
      "quatern_d       : 0.0\n",
      "qoffset_x       : -94.5\n",
      "qoffset_y       : -108.95783\n",
      "qoffset_z       : -67.87952\n",
      "srow_x          : [  3.    0.    0.  -94.5]\n",
      "srow_y          : [   0.         3.         0.      -108.95783]\n",
      "srow_z          : [  0.        0.        4.      -67.87952]\n",
      "intent_name     : b''\n",
      "magic           : b'n+1'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "\n",
    "# Directory where your data set resides. This needs to be customized\n",
    "dataDir = '/home/satoru/Teaching/fMRI_Fall_2018/Data/ds102'\n",
    "\n",
    "# reading in the fMRI data array\n",
    "f_fMRI = os.path.join(dataDir,'sub-26/func/sub-26_task-flanker_run-2_bold.nii.gz')\n",
    "fMRI = nib.load(f_fMRI)   # image object\n",
    "\n",
    "# priting out the header information\n",
    "hdr_fMRI = fMRI.header\n",
    "print(hdr_fMRI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of methods associated with the NIfTI header that provide you information you may be interested. First, the image dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 40, 146)\n"
     ]
    }
   ],
   "source": [
    "# image dimension\n",
    "print(hdr_fMRI.get_data_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the first 3 elements (**`64  64  40`**) show the number of voxels in the x, y, and z dimensions. The 4th element (**`146`**) is the number of time points in this fMRI time series. \n",
    "\n",
    "Next, data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int16\n"
     ]
    }
   ],
   "source": [
    "# data type\n",
    "print(hdr_fMRI.get_data_dtype())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that, the data format for each voxel value is **`int16`**, or 16-bit integer. If you ever want to change the data type to another format, you can use the **`set_data_dtype()`** method associated with the header. For example,\n",
    "```python\n",
    "hdr_fMRI.set_data_dtype('float32')\n",
    "```\n",
    "sets the data type to be 32-bit float.\n",
    "\n",
    "The voxel size can be viewed by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3.0, 3.0, 4.0, 2.0)\n"
     ]
    }
   ],
   "source": [
    "# voxel size\n",
    "print(hdr_fMRI.get_zooms())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the first 3 elements correspond to voxel sizes in mm in x-, y-, and z-directions, respectively. The last element refers to the repetition time (TR, time between scans) in seconds.\n",
    "\n",
    "### Exercise\n",
    "1. **Header info, T1 image**. Get the image dimension, data type, and voxel size from the T1 image of a randomly selected subject from the data set `ds102`. Post the resulting information (rather than the code) on Canvas.\n",
    "2. **Header info, fMRI data, ds114**. Get the image dimension, data type, and voxel size from the fMRI data of a randomly selected subject from the data set `ds114`. Post the resulting information (rather than the code) on Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful piece of information in the NIfTI header is the affine information. It is a 4x4 matrix that lets you transform the voxel coordinates. This is what the affine matrix looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<AffineInfo.py>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  -1.           -0.           -0.           -1.44578552]\n",
      " [  -0.            1.           -0.         -127.5       ]\n",
      " [   0.            0.            1.         -125.33132935]\n",
      " [   0.            0.            0.            1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "\n",
    "# Directory where your data set resides. This needs to be customized\n",
    "dataDir = '/home/satoru/Teaching/fMRI_Fall_2018/Data/ds102'\n",
    "\n",
    "# reading in the T1 data array\n",
    "f_sMRI = os.path.join(dataDir,'sub-26/anat/sub-26_T1w.nii.gz')\n",
    "sMRI = nib.load(f_sMRI)\n",
    "X_sMRI = sMRI.get_data()\n",
    "\n",
    "# affine matrix\n",
    "print(sMRI.affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that, although this information is embedded in the header, we use the **`affine`** method associated with the *image object*, not the *header*. So, why should we care about this matrix? This matrix lets you transform array indices into the voxel coordinates in the brain space. Say, you want to see where the voxel `[85, 110, 140]` is located in the brain space (in terms of mm). \n",
    "\n",
    "To do so, you create a vector with the desired indices, plus 1 as the fourth element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example voxel indices\n",
    "xyz = np.array([[85, 110, 140]])\n",
    "xyz1 = np.hstack([xyz,np.array([[1]])]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 85],\n",
       "       [110],\n",
       "       [140],\n",
       "       [  1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xyz1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you multiply this with the affine matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming array indices to brain space coordinate\n",
    "A = sMRI.affine\n",
    "brain_xyz = np.dot(A,xyz1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-86.44578552],\n",
       "       [-17.5       ],\n",
       "       [ 14.66867065],\n",
       "       [  1.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain_xyz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the first 3 elements correspond to the voxel coordinate in the brain space, in terms of mm. You can verify this with an image viewer. For example, in FSL,\n",
    "\n",
    "<img style='width: 650px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Affine_Viewer.png?raw=true' alt='Affine viewer'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to transform the voxel coordinates in the brain space (in mm) to the corresponding array indices, simply finding the inverse of the affine matrix. For example, take the coordinate `[0, 0, 0]`mm in the brain space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voxel coordinate in mm\n",
    "xyzmm = np.array([[0, 0, 0]])\n",
    "xyz1mm = np.hstack([xyzmm,np.array([[1]])]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xyz1mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming brain space coordinate (in mm) to array indices\n",
    "invA = np.linalg.inv(A)\n",
    "voxel_xyz = np.dot(invA,xyz1mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.44578552],\n",
       "       [127.5       ],\n",
       "       [125.33132935],\n",
       "       [  1.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voxel_xyz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can check with an image viewer.\n",
    "\n",
    "<img style='width: 650px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Affine_Inverse.png?raw=true' alt='Affine viewer'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this image is the raw data, thus the center of the image `[0, 0, 0]`(in the brain space) is at an arbitrary location. During the preprocessing, the center is usually placed in the anterior commissure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NIfTI data matrix\n",
    "\n",
    "This portion of a NIfTI file consists of a series of 3D or 4D voxel intensities stored in a long sequence of numbers. There are several conventions to store voxel intensities such as:\n",
    "  * **RAS**\n",
    "      * First axis: x-axis left to **R**ight\n",
    "      * Second axis: y-axis posterior to **A**nterior\n",
    "      * Third axis: z-axis inferior to **S**uperior\n",
    "  * **LAS**\n",
    "      * First axis: x-axis right to **L**eft\n",
    "      * Second axis: y-axis posterior to **A**nterior\n",
    "      * Third axis: z-axis inferior to **S**uperior\n",
    "      \n",
    "Unless your data set consists of images acquired from different scanners with different protocols, you do not have to worry about how data are stored in a NIfTI file. Most image viewers and analysis software tools can display and process images in the desired orientation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Radiological vs. Neurological\n",
    "\n",
    "One thing you have to deal with, in your analysis as well as when you read the neuroimaging literature, is the orientation how the brain is displayed. There are two conventions:\n",
    "  * Neurological: \n",
    "      * Patient's left is displayed on the left\n",
    "  * Radiological:\n",
    "      * Patient's left is displayed on the right\n",
    "      \n",
    "<img style='width: 400px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Affine_radio_neuro.jpg?raw=true' alt='Neurological or radiological'/>\n",
    "\n",
    "\n",
    "When you examine image data, make sure which side of the subject is displayed on which side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIDS\n",
    "<hr style=\"height:1px;border:none\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is BIDS?\n",
    "\n",
    "BIDS stands for Brain Imaging Data Structure. BIDS is a systematic way of organizing neurimaging data with a consistent structure. Before BIDS, each lab organized their neuroimaging data in their own way. This was a big obstacle in sharing data across different labs. Moreover, porting of any processing pipeline, from one lab to another, required a significant re-coding in order to accommodate different data organization. \n",
    "\n",
    "The complete specification of the BIDS is available from the [BIDS's web site](http://bids.neuroimaging.io/bids_spec.pdf). Here are highlights of BIDS:\n",
    "\n",
    "* Hierarchical organization of directories\n",
    "* Consistent naming of files and directories\n",
    "* Specific file formats\n",
    "\n",
    "## Hierarchical directory organization\n",
    "\n",
    "In BIDS, directories are organized in a hierarchical fashion. From the top,\n",
    "  * **Data set**. This is the directory containing all the data associated with a particular neuroimaging experiment.\n",
    "  * **Subject**. Each subject or animal in the experiment has a directory. All data pertaining to that subject are stored there.\n",
    "     * It should start with **`sub-`**, followed by a string identifying a subject.\n",
    "        * For example, **`sub-control01`**, **`sub-patient15`**, or simply **`sub-03`**.\n",
    "     * The subject number should be zero-padded. For example, **`01`** or **`001`** instead of **`1`**. This facilitates sorting of subjects according to their numbers.\n",
    "  * **Session** (if applicable). A session refers to a visit in a longitudinal study, or a scanning session in a multi-session experiment. If there is only one session in the experiment, then this can be disregarded. \n",
    "     * It should start with **`ses-`** followed by the string identifying each session.\n",
    "        * For example, **`ses-before`**, **`ses-time0`**, or **`ses-posttest`**.\n",
    "  * **Modality**. This is a directory containing imaging and other data files associated with a particular imaging modality (e.g., structural images (T1 weighted images), functional images, diffusion weighted images, MEG, PET).\n",
    "     * Suggested directory names are:\n",
    "        * **`anat`** Structural image data, modalities including T1-weighted, T2-weighted, FLAIR, and proton density.\n",
    "        * **`func`** Functional MRI data.\n",
    "        * **`dwi`** Diffusion weighted images.\n",
    "        * **`meg`** MEG (Magnetoencephalography)\n",
    "        \n",
    "***NB: Directory names are case sensitive. Use of lower case letters recommended.***\n",
    "\n",
    "### Example\n",
    "\n",
    "Here is the directory organization for the first two subjects for the `ds114` data set, viewed by the **`tree`** command.\n",
    "```\n",
    "../Data/ds114/\n",
    "|...\n",
    "|-- sub-01\n",
    "|   |-- ses-retest\n",
    "|   |   |-- anat\n",
    "|   |   |   `-- sub-01_ses-retest_T1w.nii.gz\n",
    "|   |   |-- dwi\n",
    "|   |   |   `-- sub-01_ses-retest_dwi.nii.gz\n",
    "|   |   `-- func\n",
    "|   |       |-- sub-01_ses-retest_task-covertverbgeneration_bold.nii.gz\n",
    "|   |       |...\n",
    "|   |       `-- sub-01_ses-retest_task-overtwordrepetition_bold.nii.gz\n",
    "|   `-- ses-test\n",
    "|       |-- anat\n",
    "|       |   `-- sub-01_ses-test_T1w.nii.gz\n",
    "|       |-- dwi\n",
    "|       |   `-- sub-01_ses-test_dwi.nii.gz\n",
    "|       `-- func\n",
    "|           |-- sub-01_ses-test_task-covertverbgeneration_bold.nii.gz\n",
    "|           |...\n",
    "|           `-- sub-01_ses-test_task-overtwordrepetition_bold.nii.gz\n",
    "|-- sub-02\n",
    "|   |-- ses-retest\n",
    "|   |   |-- anat\n",
    "|   |   |   `-- sub-02_ses-retest_T1w.nii.gz\n",
    "|   |   |-- dwi\n",
    "|   |   |   `-- sub-02_ses-retest_dwi.nii.gz\n",
    "|   |   `-- func\n",
    "|   |       |-- sub-02_ses-retest_task-covertverbgeneration_bold.nii.gz\n",
    "|   |       |...\n",
    "|   |       `-- sub-02_ses-retest_task-overtwordrepetition_bold.nii.gz\n",
    "|   `-- ses-test\n",
    "|       |-- anat\n",
    "|       |   `-- sub-02_ses-test_T1w.nii.gz\n",
    "|       |-- dwi\n",
    "|       |   `-- sub-02_ses-test_dwi.nii.gz\n",
    "|       `-- func\n",
    "|           |-- sub-02_ses-test_task-covertverbgeneration_bold.nii.gz\n",
    "|           |...\n",
    "|           `-- sub-02_ses-test_task-overtwordrepetition_bold.nii.gz\n",
    "|-- sub-03\n",
    "|...\n",
    "```\n",
    "\n",
    "In this study, each subject underwent two sessions (`test` and `retest`). Within each session, there are directories for structural MRI (`anat`), fMRI (`func`), and diffusion images (`dwi`).\n",
    "\n",
    "## Image data and how to name them\n",
    "\n",
    "The recommended image format for BIDS is NIfTI (`.nii`). It can be either uncompressed or gzipped (**`.nii.gz`**).\n",
    "\n",
    "### Structural image data naming convention (`anat`)\n",
    "\n",
    "A structural image data file should be named by following this convention:\n",
    "```\n",
    "sub-<participant_label>[_ses-<session_label>]_<modality_label>.nii[.gz]\n",
    "```\n",
    "Here, the elements are:\n",
    "  * **`sub-<participant_label>`**: Subject identifier, as explained above.\n",
    "  * **`ses-<session_label>`**: Session identifier, where applicable, as explained above. If there is only one session in the experiment, this can be disregarded.\n",
    "  * **`<modality_label>`**: Modality label. There are different labels:\n",
    "     * **`T1w`**: T1-weighted (typical structural MRI)\n",
    "     * **`T2w`**: T2-weighted\n",
    "     * **`PD`**: Proton density\n",
    "\n",
    "In addition to these, you can embed additional information to the file name such as acquisition parameters, contrast enhancement, reconstruction algorithms, and runs. You can find the additional information in the BIDS specification.\n",
    "\n",
    "***Examples***:\n",
    "```\n",
    "sub-01_ses-retest_T1w.nii.gz\n",
    "sub-10_T1w.nii.gz\n",
    "```\n",
    "\n",
    "### Functional image data naming convention (`func`)\n",
    "\n",
    "A functional image data file should be named by following this convention:\n",
    "```\n",
    "sub-<participant_label>[_ses-<session_label>]_task-<task_label>[_run-<index>]_bold.nii[.gz]\n",
    "```\n",
    "Here, the elements are:\n",
    "  * **`sub-<participant_label>`**: Subject identifier, as explained above.\n",
    "  * **`ses-<session_label>`**: Session identifier, where applicable, as explained above. If there is only one session in the experiment, this can be disregarded.\n",
    "  * **`task-<task_label>`**: Task identifier. Here, you need to name the task with a **`<task_label>`** consisting of letters and/or numbers (no special characters). \n",
    "     * Examples: `nback`, `stroop`, `fingertapping`, `rest`\n",
    "  * **`run-<index>`**: Run index. Say, you have multiple runs of the same task in your experiment, you can distinguish them by including the run index. A run can be indicated by a single number (no zero padding is necessary). If there is only one run, then you can ignore this.\n",
    "     * Examples: `run-1`, `run-2`\n",
    "     \n",
    "In addition to these, you can embed additional information to the file name. You can find the additional information in the BIDS specification.\n",
    "\n",
    "***Examples***\n",
    "```\n",
    "sub-07_ses-test_task-overtverbgeneration_bold.nii.gz\n",
    "sub-12_task-flanker_run-2_bold.nii.gz\n",
    "```\n",
    "\n",
    "### Diffusion image data naming convention (`dwi`)\n",
    "\n",
    "Although we do not talk about diffusion images, it is common to acquire diffusion images during an fMRI experiment. Here is how you can name data files:\n",
    "```\n",
    "sub-<participant_label>[_ses-<session_label>][_run-<index>]_dwi.nii[.gz]\n",
    "sub-<participant_label>[_ses-<session_label>][_run-<index>]_dwi.bval\n",
    "sub-<participant_label>[_ses-<session_label>][_run-<index>]_dwi.bvec\n",
    "```\n",
    "\n",
    "Here, the elements for the name has already been explained above. One thing to note here is that you need, in addition to the NIfTI image, data files describing diffusion parameters. The **`.bvec`** file contains diffusion directions, and the **`.bval`** file contains diffusion values. The `.bvec` and `.bval` follow the format specified by FSL. For details, I refer you to the BIDS specification document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other file formats and files\n",
    "\n",
    "### Tabular files (`.tsv`)\n",
    "\n",
    "If you want to include information in a tabular format, you need to use the tab separated value format (**`.tsv`**). A `.tsv` file is easily *readable* by humans. It is ideal to store information such as participant information or task timing information. \n",
    "\n",
    "***Examples***\n",
    "\n",
    "Task information (see below for details):\n",
    "```\n",
    "onset  duration  response_time   correct   stop_trial   go_trial\n",
    "200    20        0               n/a       n/a          n/a\n",
    "```\n",
    "\n",
    "\n",
    "Participant information (**`participants.tsv`**): (Located under the data set directory)\n",
    "```\n",
    "participant_id\t gender\t  age\n",
    "sub-01\t         F\t      21.94\n",
    "sub-02\t         M\t      22.79\n",
    "sub-03\t         M\t      19.65\n",
    "...\n",
    "```\n",
    "\n",
    "\n",
    "### JSON dictionary files (`.json`)\n",
    "\n",
    "A JSON file contains pairs of keys and values, just as a dictionary in python. JSON files can be used to describe details about data sets, sessions, runs, tasks, or imaging parameters. There are a number of JSON format files with specific fields (or keys). \n",
    "\n",
    "***Examples***\n",
    "\n",
    "Image acquisition parameters:\n",
    "```\n",
    "{\n",
    "\t\"RepetitionTime\": 2.5,\n",
    "\t\"Manufacturer\": \"Siemens\",\n",
    "\t\"ManufacturerModelName\": \"Allegra\",\n",
    "\t\"MagneticFieldStrength\": 3.0,\n",
    "\t\"ScanningSequence\": \"MPRAGE\",\n",
    "\t\"MRAcquisitionType\": \"3D\",\n",
    "\t\"EchoTime\": 0.00393,\n",
    "\t\"InversionTime\": 0.90,\n",
    "\t\"FlipAngle\": 8.0\n",
    "}\n",
    "```\n",
    "\n",
    "Task description:\n",
    "```\n",
    "{\n",
    "    \"EchoTime\": 0.05,\n",
    "    \"FlipAngle\": 90,\n",
    "    \"RepetitionTime\": 5.0,\n",
    "    \"SliceTiming\": [\n",
    "        0.0,\n",
    "        1.2499999999999998,\n",
    "        0.08333333333333333,\n",
    "        ...\n",
    "        1.1666666666666665,\n",
    "        2.416666666666665\n",
    "    ],\n",
    "    \"TaskName\": \"overt_verb_generation\"\n",
    "}\n",
    "```\n",
    "\n",
    "### Required files\n",
    "\n",
    "Some data files (`.tsv` or `.json`) are required by BIDS.\n",
    "\n",
    "#### Data set description (`dataset_description.json`)\n",
    "This is a JSON file located under the main data set directory, describing the data set. The following are the fields for this file:\n",
    "\n",
    "  * **`Name`**: *REQUIRED.* Name of the dataset.\n",
    "  * **`BIDSVersion`**: *REQUIRED.* The version of the BIDS standard that was used. FYI, this particular note is base on BIDS version **1.1.1**. \n",
    "  * **`Authors`**:  *OPTIONAL.* List of individuals who contributed to the creation/curation of       ReferencesAndLinks OPTIONAL. List of references to publication that contain information on the dataset, or links.\n",
    "  * **`DatasetDOI`**: *OPTIONAL.* The Document Object Identifier of the dataset (not the\n",
    "corresponding paper).\n",
    "\n",
    "There are other recommended and optional fields. You can find more details in the BIDS specification document.\n",
    "\n",
    "***Example***\n",
    "```\n",
    "{\n",
    "    \"Name\":\"Flanker task (event-related)\",\n",
    "    \"BIDSVersion\":\"1.0.0rc3\",\n",
    "    \"License\":\"PDDL\",\n",
    "    \"Authors\":[\"Kelly AMC\",\"Uddin LQ\",\"Biswal BB\",\"Castellanos FX\",\"Milham MP\"],\n",
    "    \"HowToAcknowledge\":\"This data was obtained from the OpenfMRI database. Its accessio\n",
    "n number is ds000102\",\n",
    "    \"ReferencesAndLinks\":[\"http://www.ncbi.nlm.nih.gov/pubmed/20974260\",\"http://www.ncbi.nlm.nih.gov/pubmed/20079856\",\"http://www.ncbi.nlm.nih.gov/pubmed/17919929\"]\n",
    "}\n",
    "```\n",
    "\n",
    "#### Task events\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Other data files\n",
    "  * tsv\n",
    "  \n",
    "  * json\n",
    "     * Required for the data set\n",
    "     * Optional\n",
    "     \n",
    "* pybids"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
