{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align:center'>\n",
    "PSY 394U <b>Methods for fMRI</b>, Fall 2018\n",
    "\n",
    "\n",
    "<img style='width: 300px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Placebo_Left.png?raw=true' alt='brain blobs'/>\n",
    "\n",
    "</p>\n",
    "\n",
    "<p style='text-align:center; font-size:40px; margin-bottom: 30px;'><b> Second- and higher-level analyses </b></p>\n",
    "\n",
    "<p style='text-align:center; font-size:18px; margin-bottom: 32px;'><b> December 3, 2018</b></p>\n",
    "\n",
    "<hr style='height:5px;border:none' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data sets\n",
    "<hr style=\"height:1px;border:none\" />\n",
    "\n",
    "In the following demonstrations, I will be using first-level analysis results from the `ds114` data set. For your convenience, pre-analyzed (first-level) data sets are available for download using the links provided below. Once downloaded, you need to run the following command to uncompress and extract the data.\n",
    "\n",
    "  1. Copy the data to the desired directory\n",
    "  2. Unpack the data by the following commands:\n",
    "```\n",
    "gunzip <data file name>.tar.gz\n",
    "tar <data file name>.tar\n",
    "```\n",
    "where `<data file name>` corresponds to the file name of the downloaded `.tar` file (also known as a **tar ball**). You may not need the gunzip command if you are downloading the data on a Mac, as a Mac computer automatically gunzips a file after a download.\n",
    "\n",
    "\n",
    "\n",
    "## Fingers-foot-lips task\n",
    "\n",
    "Subjects moved fingers, foot, or lips when presented with a visual cue specifying the body parts. The subjects were instructed to move fingers and foot on their dominant side. There are three left-handed subjects in this data set. Their structural MRI, as well as fMRI data were flipped left/right so that activation loci would be on the same hemisphere as their right-handed counterparts. The first-level analysis results (processed with SPM) can be downloaded from [Box.com](https://utexas.box.com/s/5ke7555s9w610fybibhjiwa8cr4sc0fs). The contrasts for this task are:\n",
    "```python\n",
    "cont01 = ['average',        'T', conditions, [1/3., 1/3., 1/3.]]\n",
    "cont02 = ['Finger',         'T', conditions, [1, 0, 0]]\n",
    "cont03 = ['Foot',           'T', conditions, [0, 1, 0]]\n",
    "cont04 = ['Lips',           'T', conditions, [0, 0, 1]]\n",
    "cont05 = ['Finger > others','T', conditions, [1, -0.5, -0.5]]\n",
    "cont06 = ['Foot > others',  'T', conditions, [-0.5, 1, -0.5]]\n",
    "cont07 = ['Lips > others',  'T', conditions, [-0.5, -0.5, 1]]\n",
    "\n",
    "cont08 = ['activation',     'F', [cont02, cont03, cont04]]\n",
    "```\n",
    "\n",
    "The batch script for the first-level analysis (`Level1_spm.py`) can be found on [GitHub](https://github.com/sathayas/fMRIClassFall2018/blob/master/BatchScripts/Level1_spm.py). \n",
    "\n",
    "\n",
    "## Overt word repetition (OWR) task\n",
    "\n",
    "Subjects were instructed to repeat the word when they hear it through the headphone. There is only one condition for this experiment (`Task`). The first-level analysis results can be downloaded from Box.com.\n",
    "  * SPM-version\n",
    "  * FSL-version\n",
    "\n",
    "The contrasts for this task are:\n",
    "```python\n",
    "cont01 = ['activation',     'T', conditions, [1]]\n",
    "cont02 = ['deactivation',   'T', conditions, [-1]]\n",
    "```\n",
    "\n",
    "The batch script for the first-level analysis can be found on GitHub:\n",
    "  * SPM version\n",
    "  * FSL version\n",
    "\n",
    "\n",
    "## Overt verb generation (OVG) task\n",
    "\n",
    "Subjects were instructed to generate a verb associated with the noun they heard through the headphone. There is only one condition for this experiment (`Task`). The first-level analysis results can be downloaded from Box.com.\n",
    "  * SPM-version\n",
    "  * FSL-version\n",
    "\n",
    "The contrasts for this task are:\n",
    "```python\n",
    "cont01 = ['activation',     'T', conditions, [1]]\n",
    "cont02 = ['deactivation',   'T', conditions, [-1]]\n",
    "```\n",
    "\n",
    "The batch script for the first-level analysis can be found on GitHub:\n",
    "  * SPM version\n",
    "  * FSL version\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second-level analysis (one-sample T-test)\n",
    "<hr style=\"height:1px;border:none\" />\n",
    "\n",
    "\n",
    "For this exercise, we will examine the contrast **finger > others** from the `ds114` data set. We will focus on the **`ses-test`** session only.\n",
    "\n",
    "## FSL\n",
    "\n",
    "Under main FSL GUI, select **FEAT FMRI analysis**. Then under the FEAT GUI, choose the following parameters:\n",
    "\n",
    "  * Under the **Data** tab:\n",
    "     * Select **Higher-level analysis** from the pull-down menu\n",
    "     * Select **Inputs are 3D cope images...** from the pull-down menu\n",
    "     * **Number of inputs**: 10\n",
    "     * **Select cope images**: Paste a list of files using the **Paste** button.\n",
    "     ```\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_fsl/sub-01/ses-test/run0.feat/stats/cope5.nii.gz\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_fsl/sub-02/ses-test/run0.feat/stats/cope5.nii.gz\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_fsl/sub-03/ses-test/run0.feat/stats/cope5.nii.gz\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_fsl/sub-04/ses-test/run0.feat/stats/cope5.nii.gz\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_fsl/sub-05/ses-test/run0.feat/stats/cope5.nii.gz\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_fsl/sub-06/ses-test/run0.feat/stats/cope5.nii.gz\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_fsl/sub-07/ses-test/run0.feat/stats/cope5.nii.gz\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_fsl/sub-08/ses-test/run0.feat/stats/cope5.nii.gz\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_fsl/sub-09/ses-test/run0.feat/stats/cope5.nii.gz\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_fsl/sub-10/ses-test/run0.feat/stats/cope5.nii.gz\n",
    "     ```\n",
    "     ***Note***: The location of `cope5.nii.gz` depends where you put the data on your computer.\n",
    "     * **Output directory**: I create a folder called **`OneSampleT_finger_vs_other_ses-test.gfeat`** under the **Level1_fsl** directory.\n",
    "     \n",
    "\n",
    "* Under the **Stats** tab:\n",
    "    * **Fixed effects** from the pull-down menu\n",
    "    * From **Model setup wizard**, select **single group average**\n",
    "    \n",
    "<img src=\"https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Level2_fsl_OneSampT_DesMtx.png?raw=true\" alt=\"One-sample T, FSL, design matrix\" style=\"width: 200px; float: center;\"/>\n",
    "\n",
    "* Under the **Post-stats** tab:\n",
    "  * In the **Thresholding** box:\n",
    "     * From the pull-down menu, select **Cluster** (i.e., RFT-based FWE cluster-level correction).\n",
    "     * Change the **Z threshold** to **3.09**. \n",
    "     This is the cluster-forming threshold. Why 3.09? That is because Z=3.09 corresponds to the *uncorrected threshold at p=0.001*. Note that, by default, FSL sets the Z threshold to 2.3 or p=0.01 uncorrected. Here is some useful info when you choose the cluster- forming threshold.\n",
    "        * Uncorrected p=0.05 -- Z=1.65\n",
    "        * Uncorrected p=0.01 -- Z=2.33\n",
    "        * Uncorrected p=0.005 -- Z=2.58\n",
    "        * Uncorrected p=0.001 -- Z=3.09\n",
    "        * Uncorrected p=0.0005 -- Z=3.29\n",
    "        * Uncorrected p=0.0001 -- Z=3.71\n",
    "  * Make sure **Cluster P threshold** is **0.05**. This means only the clusters with FWE-corrected p<0.05 are considered significant.\n",
    "\n",
    "* **Click Go**, and wait for 5 minutes.\n",
    "\n",
    "### Results\n",
    "\n",
    "<img src=\"https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Level2_fsl_OneSampT_Results.png?raw=true\" alt=\"One-sample T, FSL, result\" style=\"width: 700px; float: center;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPM\n",
    "\n",
    "### Specifying the model\n",
    "\n",
    "From the SPM GUI, click on **Specify 2nd-level** button.\n",
    "\n",
    "* **Directory**: Specify **`Level1_spm`** directory\n",
    "* **Design**: One-sample T-test\n",
    "  * Specify **Scans**:\n",
    "  ```\n",
    "  /Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_spm/sub-01/ses-test/con_0005.nii\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_spm/sub-02/ses-test/con_0005.nii\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_spm/sub-03/ses-test/con_0005.nii\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_spm/sub-04/ses-test/con_0005.nii\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_spm/sub-05/ses-test/con_0005.nii\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_spm/sub-06/ses-test/con_0005.nii\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_spm/sub-07/ses-test/con_0005.nii\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_spm/sub-08/ses-test/con_0005.nii\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_spm/sub-09/ses-test/con_0005.nii\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_spm/sub-10/ses-test/con_0005.nii\n",
    "```\n",
    "     ***Note***: The location of `con_0005.nii` depends where you put the data on your computer.\n",
    "\n",
    "* Click on the **Play** button\n",
    "\n",
    "<img src=\"https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Level2_spm_OneSampT_DesMtx.png?raw=true\" alt=\"One-sample T, SPM, design matrix\" style=\"width: 600px; float: center;\"/>\n",
    "\n",
    "\n",
    "\n",
    "### Estimating the model\n",
    "\n",
    "* From SPM GUI, click on **Estimate** button.\n",
    "   * Under **Select SPM.mat**, select the **`SPM.mat`** file created by the previous step.\n",
    "* Click on the **Play** button\n",
    "\n",
    "### Results\n",
    "\n",
    "* From SPM GUI, click on **Results** button.\n",
    "* Select **`SPM.mat`** for this analysis.\n",
    "* Under the **Contrast manager**:\n",
    "  * **Define new contrast**:\n",
    "     * **Name**: Activation\n",
    "     * **Type**: t-contrast\n",
    "     * **Contrast**: 1\n",
    "     * Press **Submit**\n",
    "     * Click **OK**\n",
    "  * Select **Activation**\n",
    "  * Click **Done**\n",
    "* **Apply masking**: **None**\n",
    "* **p value adjustment to control**: **none**\n",
    "* **Threshold (T or p-value)**: **0.001**\n",
    "* **Extent threshold (voxels)**: **0** (for now)\n",
    "\n",
    "<img src=\"https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Level2_spm_OneSampT_Results.png?raw=true\" alt=\"One-sample T, SPM, design matrix\" style=\"width: 700px; float: center;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second-level analysis (paired T-test)\n",
    "<hr style=\"height:1px;border:none\" />\n",
    "\n",
    "For this demonstration, we will use the first-level analysis results from the **overt verb generation (OVG)** task and the **overt word repetition (OWR)** task from the `ds114` data. In particular, we calculate the difference **OVG - OWR**. This should elucidate the area of the brain associated with generating verbs (as opposed to simply repeating words). Since each subject has two conditions (represented by two contrast images), we need to use a paired T-test to account for the fact that some contrast images originate from the same subject.\n",
    "\n",
    "\n",
    "## FSL\n",
    "\n",
    "Under main FSL GUI, select **FEAT FMRI analysis**. Then under the FEAT GUI, choose the following parameters:\n",
    "\n",
    "  * Under the **Data** tab:\n",
    "     * Select **Higher-level analysis** from the pull-down menu\n",
    "     * Select **Inputs are 3D cope images...** from the pull-down menu\n",
    "     * **Number of inputs**: 20\n",
    "     * **Select cope images**: Paste a list of files using the **Paste** button.\n",
    "     ```\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_Verb_fsl/sub-01/ses-test/task-overtverbgeneration/run0.feat/stats/cope1.nii.gz\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_Verb_fsl/sub-02/ses-test/task-overtverbgeneration/run0.feat/stats/cope1.nii.gz\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_Verb_fsl/sub-03/ses-test/task-overtverbgeneration/run0.feat/stats/cope1.nii.gz\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_Verb_fsl/sub-04/ses-test/task-overtverbgeneration/run0.feat/stats/cope1.nii.gz\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_Verb_fsl/sub-05/ses-test/task-overtverbgeneration/run0.feat/stats/cope1.nii.gz\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_Verb_fsl/sub-06/ses-test/task-overtverbgeneration/run0.feat/stats/cope1.nii.gz\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_Verb_fsl/sub-07/ses-test/task-overtverbgeneration/run0.feat/stats/cope1.nii.gz\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_Verb_fsl/sub-08/ses-test/task-overtverbgeneration/run0.feat/stats/cope1.nii.gz\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_Verb_fsl/sub-09/ses-test/task-overtverbgeneration/run0.feat/stats/cope1.nii.gz\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_Verb_fsl/sub-10/ses-test/task-overtverbgeneration/run0.feat/stats/cope1.nii.gz\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_Verb_fsl/sub-01/ses-test/task-overtwordrepetition/run0.feat/stats/cope1.nii.gz\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_Verb_fsl/sub-02/ses-test/task-overtwordrepetition/run0.feat/stats/cope1.nii.gz\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_Verb_fsl/sub-03/ses-test/task-overtwordrepetition/run0.feat/stats/cope1.nii.gz\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_Verb_fsl/sub-04/ses-test/task-overtwordrepetition/run0.feat/stats/cope1.nii.gz\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_Verb_fsl/sub-05/ses-test/task-overtwordrepetition/run0.feat/stats/cope1.nii.gz\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_Verb_fsl/sub-06/ses-test/task-overtwordrepetition/run0.feat/stats/cope1.nii.gz\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_Verb_fsl/sub-07/ses-test/task-overtwordrepetition/run0.feat/stats/cope1.nii.gz\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_Verb_fsl/sub-08/ses-test/task-overtwordrepetition/run0.feat/stats/cope1.nii.gz\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_Verb_fsl/sub-09/ses-test/task-overtwordrepetition/run0.feat/stats/cope1.nii.gz\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_Verb_fsl/sub-10/ses-test/task-overtwordrepetition/run0.feat/stats/cope1.nii.gz\n",
    "```\n",
    "     ***Note***: The location of `cope1.nii.gz` depends where you put the data on your computer.\n",
    "     * **Output directory**: I create a folder called **`PairedT_Verb_test.gfeat`** under the **Level1_Verb_fsl** directory.\n",
    "\n",
    "* Under the **Stats** tab:\n",
    "    * **Fixed effects** from the pull-down menu\n",
    "    * From **Model setup wizard**, select **two groups, paired**\n",
    "\n",
    "<img src=\"https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Level2_fsl_PairedT_DesMtx.png?raw=true\" alt=\"Paired t-test, FSL, design matrix\" style=\"width: 700px; float: center;\"/>\n",
    "\n",
    "* Under the **Post-stats** tab:\n",
    "  * In the **Thresholding** box:\n",
    "     * From the pull-down menu, select **Cluster** (i.e., RFT-based FWE cluster-level correction).\n",
    "     * Change the **Z threshold** to **3.09**. \n",
    "  * Make sure **Cluster P threshold** is **0.05**. \n",
    "\n",
    "* **Click Go**, and wait for 5 minutes.\n",
    "\n",
    "\n",
    "### Results\n",
    "\n",
    "<img src=\"https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Level2_fsl_PairedT_Results.png?raw=true\" alt=\"Paired T-test, FSL, result\" style=\"width: 700px; float: center;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPM\n",
    "\n",
    "### Specifying the model\n",
    "\n",
    "From the SPM GUI, click on **Specify 2nd-level** button.\n",
    "\n",
    "* **Directory**: Specify **`Level1_Verb_spm`** directory\n",
    "* **Design**: Specify **Paired t-test**\n",
    "  * Specify **Scans**:\n",
    "  * Under **Pairs**, specify **New: Pair**\n",
    "     * Under **Pair**, under **Scans [1,2]**, specify contrast images from `sub-01`\n",
    "     ```     /Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_Verb_spm/sub-01/ses-test/task-overtverbgeneration/con_0001.nii\n",
    "/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/BatchOutput/Level1_Verb_spm/sub-01/ses-test/task-overtwordrepetition/con_0001.nii\n",
    "```\n",
    "  * Repeat the process 9 more times to specify the remaining pairs\n",
    "     \n",
    "* Click on the **Play** button\n",
    "\n",
    "<img src=\"https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Level2_spm_PairedT_DesMtx.png?raw=true\" alt=\"One-sample T, SPM, design matrix\" style=\"width: 700px; float: center;\"/>\n",
    "\n",
    "### Estimating the model\n",
    "\n",
    "* From SPM GUI, click on **Estimate** button.\n",
    "   * Under **Select SPM.mat**, select the **`SPM.mat`** file created by the previous step.\n",
    "* Click on the **Play** button\n",
    "\n",
    "### Results\n",
    "\n",
    "* From SPM GUI, click on **Results** button.\n",
    "* Select **`SPM.mat`** for this analysis.\n",
    "* Under the **Contrast manager**:\n",
    "  * **Define new contrast**:\n",
    "     * **Name**: verb generation > word repetition\n",
    "     * **Type**: t-contrast\n",
    "     * **Contrast**: 1 -1\n",
    "        * You can omit 10 zeros after these numbers\n",
    "     * Press **Submit**\n",
    "     * Click **OK**\n",
    "  * Select **verb generation > word repetition**\n",
    "  * Click **Done**\n",
    "* **Apply masking**: **None**\n",
    "* **p value adjustment to control**: **none**\n",
    "* **Threshold (T or p-value)**: **0.001**\n",
    "* **Extent threshold (voxels)**: **0** (for now)\n",
    "\n",
    "<img src=\"https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Level2_spm_PairedT_Results.png?raw=true\" alt=\"Paired T-test, SPM, design matrix\" style=\"width: 700px; float: center;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining sessions or runs (Third-level analysis)\n",
    "<hr style=\"height:1px;border:none\" />\n",
    "\n",
    "In the `ds114` data set, there are two sessions: `test` and `retest`. Combining these sessions may potentially strengthen the activation and lead to better analysis results. So, for this demonstration, I analyze the **finger, foot, lips** task data. Here, I am using data from both sessions.\n",
    "\n",
    "## Combining sessions - second-level analysis (FSL)\n",
    "\n",
    "Under main FSL GUI, select **FEAT FMRI analysis**. Then under the FEAT GUI, choose the following parameters:\n",
    "\n",
    "  * Under the **Data** tab:\n",
    "     * Select **Higher-level analysis** from the pull-down menu\n",
    "     * Select **Inputs are 3D cope images...** from the pull-down menu\n",
    "     * **Number of inputs**: 10\n",
    "     * **Select cope images**: Paste a list of files using the **Paste** button.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
