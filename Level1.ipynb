{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align:center'>\n",
    "PSY 394U <b>Methods for fMRI</b>, Fall 2018\n",
    "\n",
    "\n",
    "<img style='width: 300px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Placebo_Left.png?raw=true' alt='brain blobs'/>\n",
    "\n",
    "</p>\n",
    "\n",
    "<p style='text-align:center; font-size:40px; margin-bottom: 30px;'><b> First-level analysis </b></p>\n",
    "\n",
    "<p style='text-align:center; font-size:18px; margin-bottom: 32px;'><b> November 19, 2018</b></p>\n",
    "\n",
    "<hr style='height:5px;border:none' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First-level analysis - theoretical background\n",
    "<hr style=\"height:1px;border:none\" />\n",
    "\n",
    "The first-level analysis refers to a statistical analysis of fMRI data on a single subject (of a single session and/or a single run). The main goal in the first-level analysis is to fit a temporal model to the fMRI data to quantify the activation of interest as contrast(s). \n",
    "\n",
    "## Predicted BOLD signals\n",
    "Say, your fMRI experiement consists of epochs of baseline and stimulus.\n",
    "\n",
    "<img style='width: 400px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Level1_ExperimentDesign.png?raw=true' alt='Experiment design'/>\n",
    "\n",
    "In this experiment, you anticipate activations associated with the stimulus, and you try to capture that with BOLD (blood oxygenation-level dependent) fMRI. However, after a neural activity, you can only observe delayed response in the resultant BOLD signal due to a hemodynamic delay. Such a delay is modeled by a function known as a **hemodynamic response function (HRF)**. The predicted BOLD signal, from an fMRI experiment, is the underlying neural activity convolved by an HRF.\n",
    "\n",
    "<img style='width: 700px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Level1_BOLDSignal.png?raw=true' alt='Predicted BOLD signal'/>\n",
    "\n",
    "In most fMRI analysis software tools, you can generate boxcar signals for predicted neural activities simply by providing event onset times and durations. There are also a number of HRF models available for you to choose from. Your predicted neural response is convolved by the HRF of your choice, so you don't have to generate predicted BOLD fMRI signals by yourself.\n",
    "\n",
    "## High-pass filtering\n",
    "\n",
    "During an fMRI experiment, BOLD fMRI signals often fluctuates slowly, the phenomenon known as the **low-frequency drift**. \n",
    "\n",
    "<img style='width: 400px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Level1_LowFreqDrift.png?raw=true' alt='Low frequency drift'/>\n",
    "\n",
    "This poses a challenge in statistical analyses of the data. Luckily low-frequency drift can be easily removed from fMRI data. Since it is low frequency, a high-pass filter can eliminate it. \n",
    "\n",
    "<img style='width: 500px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Level1_HighPass.png?raw=true' alt='High-pass filter before and after'/>\n",
    "\n",
    "A cut-off frequency of around 0.01Hz (or a period of 100s) seems to work well for typical fMRI data. \n",
    "\n",
    "\n",
    "## GLM\n",
    "\n",
    "GLM stands for **general linear model**. It is a statistical model that can be used for different types of analyses:\n",
    "  * ANOVA (analysis of variance): Comparison of group means\n",
    "  * ANCOVA (analysis of covariance): ANOVA adjusted for continuous variables\n",
    "  * Linear regression, simple & multiple\n",
    "  * T-test: Statistical test on mean(s)\n",
    "  * F-test: Statistical test to compare variances\n",
    "  \n",
    "<img style='width: 500px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Level1_GLMSimple.png?raw=true' alt='GLM for simple regression'/>\n",
    "\n",
    "For your fMRI experiment data, you can fit such a model at each voxel separately.\n",
    "\n",
    "<img style='width: 400px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Level1_GLMSimple_fMRI.png?raw=true' alt='GLM for simple regression, fMRI'/>\n",
    "\n",
    "In this case, $\\beta$ parameters from all voxels collectively form a 3D image.\n",
    "\n",
    "In a more realistic case, there are more than one regressors in a GLM. \n",
    "\n",
    "<img style='width: 500px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Level1_GLMMultiple.png?raw=true' alt='GLM for multiple regression'/>\n",
    "\n",
    "Or, using a matrix notation, one can describe this model with vectors:\n",
    "\n",
    "<img style='width: 500px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Level1_GLMMultipleMatrix.png?raw=true' alt='GLM for multiple regression, matrix notation'/>\n",
    "\n",
    "In an fMRI experiment, a GLM with multiple regressors will result in multiple beta images.\n",
    "\n",
    "<img style='width: 500px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Level1_GLMMultiple_fMRI.png?raw=true' alt='GLM for multiple regression, fMRI experiment'/>\n",
    "\n",
    "### Notes on GLM for fMRI\n",
    "***fMRI time series is temporally correlated***\n",
    "   * Not independent data points. Violation in the assumptions of an ordinary regression model\n",
    "   \n",
    "***The temporal correlation needs to be addressed somehow***\n",
    "   * **Pre-whitenening**: Temporal correlation is minimized so that data points are almost independent. \n",
    "   * **Explicitly modeling temporal correlation**: The temporal correlation between neighboring time points is estimated, and used in the statistical model. \n",
    "\n",
    "***HRF is different in different parts of the brain***\n",
    "   * **Temporal derivatives** of the predicted BOLD signal can be included also included as regressors in the GLM\n",
    "   * Inclusion of temporal derivatives can correct delays in BOLD signals\n",
    "\n",
    "***Second line of difference against subject motion***\n",
    "   * The **rigid-body transformation parameters** from the motion correction step can be included as regressors in the GLM\n",
    "   * Any motion-associated fluctuation in BOLD fMRI can be corrected.\n",
    "\n",
    "   \n",
    "## Contrasts\n",
    "\n",
    "A contrast is a linear combination of regression parameters $\\beta$s. For example,\n",
    "\n",
    "  * $\\beta_1$: Activation associated with condition 1\n",
    "  * $-\\beta_2$: Deactivation associated with condition 2\n",
    "  * $\\beta_2-\\beta_1$: Activation difference between conditions 2 and 1. (Condition 2 > Condition 1)\n",
    "  * $\\beta_3-\\beta_1$: Activation difference between conditions 3 and 1. (Condition 3 > Condition 1)\n",
    "\n",
    "Or, using a vector notation, we can describe these contrasts as\n",
    "\n",
    "$$\n",
    "    \\beta_1 = \\begin{bmatrix}1 & 0 & 0 \\end{bmatrix}\n",
    "        \\begin{bmatrix}\n",
    "           \\beta_{1} \\\\\n",
    "           \\beta_{2} \\\\\n",
    "           \\beta_{3}\n",
    "         \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    -\\beta_2 = \\begin{bmatrix}0 & -1 & 0 \\end{bmatrix}\n",
    "        \\begin{bmatrix}\n",
    "           \\beta_{1} \\\\\n",
    "           \\beta_{2} \\\\\n",
    "           \\beta_{3}\n",
    "         \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\beta_2-\\beta_1 = \\begin{bmatrix}-1 & 1 & 0 \\end{bmatrix}\n",
    "        \\begin{bmatrix}\n",
    "           \\beta_{1} \\\\\n",
    "           \\beta_{2} \\\\\n",
    "           \\beta_{3}\n",
    "         \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\beta_1+\\beta_2+\\beta_3 = \\begin{bmatrix}1 & 1 & 1 \\end{bmatrix}\n",
    "        \\begin{bmatrix}\n",
    "           \\beta_{1} \\\\\n",
    "           \\beta_{2} \\\\\n",
    "           \\beta_{3}\n",
    "         \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "In a first-level analysis, a contrast image can be calculated from beta-images. For example, then contrast $\\beta_2 - \\beta_1$ can be calculated as:\n",
    "\n",
    "<img style='width: 500px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Level1_ContrastImage.png?raw=true' alt='Contrast image example'/>\n",
    "\n",
    "Once the contrast image is generated, it is possible to perform a T-test (at each voxel separately) by calculating a T-statistic image. A T-statistic image can be calculated by dividing a contrast image by the residual standard error (SE) image, with an appropriate normalizing constant.\n",
    "\n",
    "<img style='width: 500px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Level1_TStatImage.png?raw=true' alt='T-statistic image calculation'/>\n",
    "\n",
    "In fMRI data analysis, the directionality matters. Highly positive T-statistics are associated with activations or effects described in the contrast. Highly negative T-statistics, on the other hand, represent deactivations or  negative effects.\n",
    "\n",
    "### Omnibus testing with an F-contrast\n",
    "\n",
    "Say, you are interested in the difference among any of 3 conditions. In other words, you want to examine:\n",
    "  * $\\beta_3 - \\beta_2$ (contrast vector [0 -1 1])\n",
    "  * $\\beta_3 - \\beta_1$ (contrast vector [-1 0 1])\n",
    "  * $\\beta_2 - \\beta_1$ (contrast vector [-1 1 0])\n",
    "\n",
    "You can examine each of these separately by a t-test. Or, you can examine these together collectively using an **F-contrast**. An F-contrast can be written as a matrix. In this particular example, the contrast is described by stacking the contrasts into a matrix.\n",
    "\n",
    "$$\n",
    "        \\begin{bmatrix}\n",
    "           0 & -1 & 1 \\\\\n",
    "           -1 & 0 & 1 \\\\\n",
    "           -1 & 1 & 0 \n",
    "         \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "If you are interested in an F-contrast, an F-contrast image as well as an F-statistic image can be calculated (details not shown). An F-statistic is non-directional. Thus a significantly large F-statistic may mean either activation or deactivation (or positive or negative differences), but the directionality cannot be determined by an F-statistic alone. Moreover, it is hard to determine which comparison contributed to the significant F-test outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First-level analysis - FSL approach\n",
    "<hr style=\"height:1px;border:none\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<Level1_fsl.py>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import nibabel as nib   # nibabel to read TR from image header\n",
    "import nipype.interfaces.fsl as fsl # importing FSL interface functions\n",
    "from nipype import Node, Workflow  # components to construct workflow\n",
    "from nipype.interfaces.io import DataSink  # datasink\n",
    "from nipype.algorithms import modelgen  # GLM model generator\n",
    "from nipype.interfaces.base import Bunch\n",
    "from bids.grabbids import BIDSLayout  # BIDSLayout object to specify file(s)\n",
    "\n",
    "\n",
    "# data directory\n",
    "dataDir = '/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114'\n",
    "\n",
    "# base directory - where preprocessed fMRI data is located\n",
    "baseDir = os.path.join(dataDir, 'WorkflowOutput/FSL_Preproc_fMRI')\n",
    "\n",
    "# Creating the layout object for this BIDS data set\n",
    "layout = BIDSLayout(dataDir)\n",
    "\n",
    "# pre-processed fMRI data\n",
    "imagefMRI = os.path.join(baseDir,\n",
    "                         'sub-09_ses-test_task-fingerfootlips_bold_roi_mcf_warp_smooth_masked.nii.gz')\n",
    "\n",
    "# task information file\n",
    "eventFile = layout.get(type='events',\n",
    "                       task='fingerfootlips',\n",
    "                       extensions='tsv',\n",
    "                       return_type='file')[0]\n",
    "\n",
    "\n",
    "# Output directory\n",
    "outDir = os.path.join(dataDir,'WorkflowOutput')\n",
    "\n",
    "# getting TR from the image header\n",
    "fMRI = nib.load(imagefMRI)   # image object\n",
    "hdr_fMRI = fMRI.header\n",
    "TR = hdr_fMRI['pixdim'][4]\n",
    "\n",
    "\n",
    "## Getting experiment info from the event file, into a Bunch object\n",
    "trialInfo = pd.read_table(eventFile)\n",
    "conditions = sorted(list(set(trialInfo.trial_type)))\n",
    "onsets = []\n",
    "durations = []\n",
    "\n",
    "for itrial in conditions:\n",
    "    onsets.append(list(trialInfo[trialInfo.trial_type==itrial].onset-10)) # subtracting 10s due to removing of 4 dummy scans\n",
    "    durations.append(list(trialInfo[trialInfo.trial_type==itrial].duration))\n",
    "\n",
    "subject_info = [Bunch(conditions=conditions,\n",
    "                      onsets=onsets,\n",
    "                      durations=durations,\n",
    "                      )]\n",
    "\n",
    "\n",
    "## Defining contrasts\n",
    "cont01 = ['average',        'T', conditions, [1/3., 1/3., 1/3.]]\n",
    "cont02 = ['Finger',         'T', conditions, [1, 0, 0]]\n",
    "cont03 = ['Foot',           'T', conditions, [0, 1, 0]]\n",
    "cont04 = ['Lips',           'T', conditions, [0, 0, 1]]\n",
    "cont05 = ['Finger < others','T', conditions, [-1, 0.5, 0.5]]\n",
    "cont06 = ['Foot < others',  'T', conditions, [0.5, -1, 0.5]]\n",
    "cont07 = ['Lips > others',  'T', conditions, [-0.5, -0.5, 1]]\n",
    "\n",
    "cont08 = ['activation',     'F', [cont02, cont03, cont04]]\n",
    "\n",
    "contrast_list = [cont01, cont02, cont03, cont04, cont05, cont06, cont07, cont08]\n",
    "\n",
    "\n",
    "# model specification\n",
    "modelspec = Node(modelgen.SpecifyModel(functional_runs=imagefMRI,\n",
    "                                       subject_info=subject_info,\n",
    "                                       input_units='secs',\n",
    "                                       time_repetition=TR,\n",
    "                                       high_pass_filter_cutoff=100),\n",
    "                 name=\"modelspec\")\n",
    "\n",
    "# first-level design\n",
    "level1design = Node(fsl.Level1Design(bases={'dgamma':{'derivs': True}},\n",
    "                                     interscan_interval=TR,\n",
    "                                     model_serial_correlations=True,\n",
    "                                     contrasts=contrast_list),\n",
    "                    name=\"level1design\")\n",
    "\n",
    "# creating all the other files necessary to run the model\n",
    "modelgen = Node(fsl.FEATModel(),\n",
    "                name='modelgen')\n",
    "\n",
    "# then running through FEAT\n",
    "feat = Node(fsl.FEAT(),\n",
    "            name=\"feat\")\n",
    "\n",
    "# creating datasink to collect outputs\n",
    "datasink = Node(DataSink(base_directory=outDir), \n",
    "                name='datasink')\n",
    "\n",
    "\n",
    "# creating the workflow\n",
    "firstLevel = Workflow(name=\"Level1_FSL\", base_dir=outDir)\n",
    "\n",
    "# connecting nodes\n",
    "firstLevel.connect([(modelspec, level1design, [('session_info', 'session_info')])])\n",
    "firstLevel.connect([(level1design, modelgen, [('fsf_files', 'fsf_file'),\n",
    "                                              ('ev_files','ev_files')])])\n",
    "firstLevel.connect([(level1design, feat, [('fsf_files', 'fsf_file')])])\n",
    "firstLevel.connect([(feat, datasink, [('feat_dir', 'FSL_Level1.@feat')])])\n",
    "\n",
    "# writing out graph\n",
    "firstLevel.write_graph(graph2use='orig', dotfilename='graph_orig.dot')\n",
    "\n",
    "# showing the graph\n",
    "plt.figure(figsize=[10,10])\n",
    "img=mpimg.imread(os.path.join(outDir,\"Level1_FSL\",\"graph_orig_detailed.png\"))\n",
    "imgplot = plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# running the workflow\n",
    "firstLevel.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First-level analysis - SPM approach\n",
    "<hr style=\"height:1px;border:none\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<Level1_spm.py>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import nibabel as nib   # nibabel to read TR from image header\n",
    "import nipype.interfaces.spm as spm # importing SPM interface functions\n",
    "from nipype import Node, Workflow  # components to construct workflow\n",
    "from nipype.interfaces.io import DataSink  # datasink\n",
    "from nipype.algorithms import modelgen  # GLM model generator\n",
    "from nipype.interfaces.base import Bunch\n",
    "from bids.grabbids import BIDSLayout  # BIDSLayout object to specify file(s)\n",
    "\n",
    "\n",
    "# data directory\n",
    "dataDir = '/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114'\n",
    "\n",
    "# base directory - where preprocessed fMRI data is located\n",
    "baseDir = os.path.join(dataDir, 'WorkflowOutput/SPM_Preproc_fMRI')\n",
    "\n",
    "# Creating the layout object for this BIDS data set\n",
    "layout = BIDSLayout(dataDir)\n",
    "\n",
    "# pre-processed fMRI data\n",
    "imagefMRI = os.path.join(baseDir,\n",
    "                         'swrsub-09_ses-test_task-fingerfootlips_bold.nii')\n",
    "\n",
    "# task information file\n",
    "eventFile = layout.get(type='events',\n",
    "                       task='fingerfootlips',\n",
    "                       extensions='tsv',\n",
    "                       return_type='file')[0]\n",
    "\n",
    "# brain mask image\n",
    "#imageMask = '/usr/local/spm12/tpm/TPM.nii'\n",
    "imageMask = '/Users/sh45474/SoftwareTools/spm12/tpm/mask_ICV.nii'\n",
    "\n",
    "# Output directory\n",
    "outDir = os.path.join(dataDir,'WorkflowOutput')\n",
    "\n",
    "# TR for the fMRI time series\n",
    "TR = 2.5\n",
    "\n",
    "\n",
    "## Getting experiment info from the event file, into a Bunch object\n",
    "trialInfo = pd.read_table(eventFile)\n",
    "conditions = sorted(list(set(trialInfo.trial_type)))\n",
    "onsets = []\n",
    "durations = []\n",
    "\n",
    "for itrial in conditions:\n",
    "    onsets.append(list(trialInfo[trialInfo.trial_type==itrial].onset)) \n",
    "    durations.append(list(trialInfo[trialInfo.trial_type==itrial].duration))\n",
    "\n",
    "subject_info = [Bunch(conditions=conditions,\n",
    "                      onsets=onsets,\n",
    "                      durations=durations,\n",
    "                      )]\n",
    "\n",
    "\n",
    "## Defining contrasts\n",
    "cont01 = ['average',        'T', conditions, [1/3., 1/3., 1/3.]]\n",
    "cont02 = ['Finger',         'T', conditions, [1, 0, 0]]\n",
    "cont03 = ['Foot',           'T', conditions, [0, 1, 0]]\n",
    "cont04 = ['Lips',           'T', conditions, [0, 0, 1]]\n",
    "cont05 = ['Finger < others','T', conditions, [-1, 0.5, 0.5]]\n",
    "cont06 = ['Foot < others',  'T', conditions, [0.5, -1, 0.5]]\n",
    "cont07 = ['Lips > others',  'T', conditions, [-0.5, -0.5, 1]]\n",
    "\n",
    "cont08 = ['activation',     'F', [cont02, cont03, cont04]]\n",
    "\n",
    "contrast_list = [cont01, cont02, cont03, cont04, cont05, cont06, cont07, cont08]\n",
    "\n",
    "\n",
    "# specifying the model\n",
    "modelspec = Node(modelgen.SpecifySPMModel(functional_runs=imagefMRI,\n",
    "                                          input_units='secs',\n",
    "                                          output_units='secs',\n",
    "                                          time_repetition=TR,\n",
    "                                          high_pass_filter_cutoff=100,\n",
    "                                          subject_info=subject_info),\n",
    "                 name=\"modelspec\")\n",
    "\n",
    "# First-level model\n",
    "level1design = Node(spm.Level1Design(bases={'hrf': {'derivs': [1, 0]}},\n",
    "                                     timing_units='secs',\n",
    "                                     interscan_interval=TR,\n",
    "                                     model_serial_correlations='AR(1)',\n",
    "                                     mask_image=imageMask),\n",
    "                    name=\"level1design\")\n",
    "\n",
    "# EstimateModel - estimate the parameters of the model\n",
    "level1estimate = Node(spm.EstimateModel(estimation_method={'Classical': 1}),\n",
    "                      name=\"level1estimate\")\n",
    "\n",
    "# EstimateContrast - estimates contrasts\n",
    "level1conest = Node(spm.EstimateContrast(contrasts=contrast_list),\n",
    "                    name=\"level1conest\")\n",
    "\n",
    "# creating datasink to collect outputs\n",
    "datasink = Node(DataSink(base_directory=outDir), \n",
    "                name='datasink')\n",
    "\n",
    "\n",
    "# Initiation of the 1st-level analysis workflow\n",
    "l1analysis = Workflow(name='Level1_SPM', base_dir=outDir)\n",
    "\n",
    "\n",
    "# Connect up the 1st-level analysis components\n",
    "l1analysis.connect([(modelspec, level1design, [('session_info','session_info')]),\n",
    "                    (level1design, level1estimate, [('spm_mat_file','spm_mat_file')]),\n",
    "                    (level1estimate, level1conest, [('spm_mat_file','spm_mat_file'),\n",
    "                                                    ('beta_images','beta_images'),\n",
    "                                                    ('residual_image','residual_image')]),\n",
    "                    (level1conest, datasink, [('spm_mat_file', 'SPM_Level1.@spm_mat'),\n",
    "                                              ('spmT_images', 'SPM_Level1.@T'),\n",
    "                                              ('con_images', 'SPM_Level1.@con'),\n",
    "                                              ('spmF_images', 'SPM_Level1.@F'),\n",
    "                                              ('ess_images', 'SPM_Level1.@ess'),\n",
    "                                              ]),\n",
    "                    ])\n",
    "\n",
    "\n",
    "# writing out graph\n",
    "l1analysis.write_graph(graph2use='orig', dotfilename='graph_orig.dot')\n",
    "\n",
    "# showing the graph\n",
    "plt.figure(figsize=[10,10])\n",
    "img=mpimg.imread(os.path.join(outDir,\"Level1_SPM\",\"graph_orig_detailed.png\"))\n",
    "imgplot = plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# running the workflow\n",
    "l1analysis.run()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "**First-level workflow, `ds102`**. Write a program with a workflow for the first-level analysis for the `ds102` you processed for your Homework Assignment 4. You may choose either `run1` or `run2`. Post the code on Canvas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
